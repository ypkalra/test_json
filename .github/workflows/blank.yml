name: Download and Chunk File

on:
  push:
    branches:
      - main

env:
  AWS_REGION: us-east-1
  AWS_ACCESS_KEY_ID: "A6SzQAhjbOmdEtogvcnN07c/biKhguTgAiOuZwEW"
  AWS_SECRET_ACCESS_KEY: "AKIATHS5MDWQZPHHXD7I"
  S3_BUCKET: yashbucket-0622
  FILE_KEY: ip_addresses.csv
  CHUNK_SIZE: 100  # Specify the chunk size in bytes

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.x'

      - name: Install required dependencies
        run: |
          python -m pip install --upgrade pip
          pip install boto3

      - name: Download file from S3 bucket
        run: |
          python -c "import boto3; s3 = boto3.client('s3', region_name='${{ env.AWS_REGION }}'); s3.download_file('${{ env.S3_BUCKET }}', '${{ env.FILE_KEY }}', 'downloaded-file.txt')"

      - name: Chunk the fileadd
        run: |
          $chunkSize = ${{ env.CHUNK_SIZE }}
          $filePath = "downloaded-file.txt"
          $chunkIndex = 0

          $fileStream = [System.IO.File]::OpenRead($filePath)
          $buffer = New-Object byte[] $chunkSize

          while ($fileStream.Position -lt $fileStream.Length) {
              $bytesRead = $fileStream.Read($buffer, 0, $chunkSize)
              $chunkFile = "chunk-$chunkIndex.txt"
              [System.IO.File]::WriteAllBytes($chunkFile, $buffer, 0, $bytesRead)
              $chunkIndex++
          }

          $fileStream.Dispose()

      - name: Upload chunks to artifact
        uses: actions/upload-artifact@v2
        with:
          name: chunks
          path: |
            chunk-*.json
